\input{header}


\areaset[66pt]{415pt}{600pt}


\begin{document}
\title{WEKA BLAAAA}
\author{Fabian Langguth, Sebastian Koch}
\date{November 2010}

\maketitle

\section{Aufgabe 1 Regellernen} % (fold)
\label{sec:aufgabe_1_regellernen}

F\"ur diese Aufgabe benutzen wir die Datens\"atze \emph{glass, iris} und \emph{splice}.
\emph{glass} wurde f\"ur den Prism-Learner mit dem Discretize-Filter verwendet (\emph{java weka.filters.supervised.attribute.Discretize -i glass.arff -o glass\_nom.arff -R 1,2,3,4,5,6,7,8,9 -c last}).\\

Anzahl der Regeln \\
\begin{tabular}{c|c|c|c}
	             & glass & iris & splice \\ \hline
Conjunctive Rule &   1   &  1   &   1    \\ \hline
JRip             &   8   &  4   &   14   \\ \hline
Prism	         &   63  &  16   &  3176    \\
\end{tabular}\\ \\

Gesamtanzahl der Bedingungen \\
\begin{tabular}{c|c|c|c}
	             & glass & iris & splice \\ \hline
Conjunctive Rule &   2   &  1   &   1    \\ \hline
JRip             &  18   &  3   &   55   \\ \hline
Prism	         &  385  & 51   &   3176   \\
\end{tabular}\\ \\

Anzahl der vorhergesagten Klassen \\
\begin{tabular}{c|c|c|c}
	             & glass & iris & splice \\ \hline
Conjunctive Rule &   1   &  1   &   1    \\ \hline
JRip             &   6   &  3   &   3    \\ \hline
Prism	         &   6   &  3   &   3    \\
\end{tabular}\\ \\


Eine Default Rule existiert nur bei JRip. Dort wird als Defaultklasse \"ublicherweise die Klasse gew\"ahlt, die am h\"aufigsten im Datensatz vorkommt. 

Der Datensatz \emph{iris} l\"asst sich am einfachsten lernen, da man hier besonders wenig Regeln und besonders wenig Bedingungen ben\"otigt.


% section aufgabe_1_regellernen (end)

\section{Aufgabe 2 Evaluation von Regellernern} % (fold)
\label{sec:aufgabe_2_evaluation_von_regellernern}

\begin{tabular}{c|c|c|c|c|c}
				Datensatz         & 1x5  & 1x10 & 1x20 & LOO  & Trainingsmenge   \\ \hline
				\emph{glass}      & 67.3 & 61.8 & 60.7 & 61.7 & 85.98   \\ \hline
				\emph{iris}       & 92.0 & 88.0 & 96.0 & 93.3 & 96.0    \\ \hline
				\emph{audiology}  & 67.3 & 66.4 & 69.9 & 69.9 & 76.1    \\ \hline
				\emph{ionosphere} & 89.2 & 92.0 & 90.0 & 89.2 & 100   \\ \hline
				\emph{yeast}      & 56.5 & 57.7 & 57.7 & 59.4 & 67.8   \\ \hline
\end{tabular}
% TODO: Qualitaet einschaetzen

\begin{tabular}{c|c|c|c|c|c}
				Datensatz         & 10x10    \\ \hline
				\emph{glass}      & 67.3     \\ \hline
				\emph{iris}       & 92.0     \\ \hline
				\emph{audiology}  & 67.3     \\ \hline
				\emph{ionosphere} & 89.2     \\ \hline
				\emph{yeast}      & 56.5     \\ \hline
\end{tabular}

% TODO: fuerht eine geschickte auswahl zu besseren abschaetzungen?

\begin{tabular}{c|c}
				Datensatz         & Validierungsmenge    \\ \hline
				\emph{glass}      & 73.1     \\ \hline
				\emph{iris}       & 93.3     \\ \hline
				\emph{audiology}  & 67.3   \\ \hline
				\emph{ionosphere} & 84.6   \\ \hline
				\emph{yeast}      & 56.1 \\ \hline
\end{tabular}

% TODO: wie war die abschaetzung?
% 10x10 Cross-Validation war grob am genausten

% section aufgabe_2_evaluation_von_regellernern (end)
\section{Aufgabe 3 ROC-Kurven}
\label{sec:aufgabe_3_ROC_kurven}

Datensatz: glass

\begin{tabular}{c|c|c|c|c}
				Regellerner       & \emph{build wind float} & \emph{containers} & \emph{tableware}  \\ \hline
				\emph{J48}			& 0.81 & 0.87 & 0.93  \\ \hline
				\emph{Naive Bayes}  & 0.71 & 0.84 & 0.98  
\end{tabular}


% section aufgabe_3_ROC_kurven (end)
\section{Aufgabe 4 Entscheidungsb\"aume}
\label{sec:aufgabe_4_entscheidungsbaume}

Datensatz: contact lenses, kr-vs-kp

Area under ROC curve

\begin{tabular}{c|c|c|c}
				Regellerner       & \emph{soft} & \emph{hard} & \emph{none}  \\ \hline
				\emph{J48 - unpruned} &  &  &   \\ \hline
				\emph{J48 - pruned}  &  &  &  \\ \hline
				\emph{ID3}  &  &  &  \\ \hline
\end{tabular}

Accuracy

\begin{tabular}{c|c|c}
				Regellerner       & \emph{contact lenses} & \emph{kr-vs-kp}  \\ \hline
				\emph{J48 - pruned} &   &   \\ \hline
				\emph{J48 - unpruned}  & &  \\ \hline
				\emph{ID3}  &  \\ \hline
\end{tabular}




%section aufgabe_4_entscheidungsbaume (end)

\section{Aufgabe 5 Nearest Neighbour}
\label{sec:aufgabe_4_nearest_neighbour}

Accuracy

\begin{tabular}{c|c|c}
                k-NN       & \emph{contact lenses} & \emph{kr-vs-kp}  \\ \hline
				\emph{k = 1} & 79.17  & 96.28  \\ \hline
				\emph{k = 3} & 79.17  & 96.50  \\ \hline
				\emph{k = 5} & 66.67  & 96.03  \\ \hline
				\emph{k = 7} & 58.33  & 95.40  \\ \hline
				\emph{k = 9} & 58.33  & 95.24  \\ \hline
				\emph{k = 11} & 58.33  & 95.06  \\ \hline
\end{tabular}

%section aufgabe_4_nearest_neighbour (end)


\section{Aufgabe 6 Regressionsb\"aume}
\label{sec:aufgabe_6_regressionsbaume}


Commandlines: 

regression tree, unpruned
java -cp WEKAPATH weka.classifiers.trees.M5P -R -N -i -t Regression/housing.arf

regression tree, pruned
java -cp WEKAPATH weka.classifiers.trees.M5P -R -i -t Regression/housing.arf

model tree, unpruned
java -cp WEKAPATH weka.classifiers.trees.M5P -i -N -t Regression/housing.arf

model tree, pruned
java -cp WEKAPATH weka.classifiers.trees.M5P -i -t Regression/housing.arf

\begin{table}
\begin{tabular}{c|c|c|c|c|c|c|c|c}
                Datensatz  & \emph{R P MAE } & \emph{R U MAE} & \emph{M P MAE} & \emph{M P MAE} & 
\emph{R P RMSE} & \emph{R U RMSE} & \emph{M P RMSE} & \emph{M P RMSE} \\ \hline
\emph{auto-price}  & 2096.37 & 2075.07& 1403.20 & 1466.56 & 3336.37  & 3287.12 & 2094.59 & 2171.16 \\ \hline
\emph{concrete}    & 6.77 & 6.48& 4.27 & 4.74 &8.68 & 8.33 & 5.89 & 6.36 \\ \hline
\emph{housing}     & 3.29 & 3.20& 2.39 & 2.50 & 4.82 & 4.72 & 3.71 & 3.75 \\ \hline
\emph{stock}       & 1.19 & 1.17& 0.67 & 0.67 & 1.60 & 1.59 & 0.93 & 0.94 \\ \hline
\emph{winequality} & 0.55 & 0.53& 0.51 & 0.55 & 0.72 & 0.70 & 0.68 & 0.71   
\end{tabular}
\caption{R: regression, M: model, U: unpruned, P: pruned, MAE: mean absolute error, RMSE: root mean squared error}
\end{table}



java -cp WEKAPATH weka.classifiers.trees.M5P -R -N -M 1 -i -t regression.arff -T regression\_test.arff


MAE: 0.61 
RMSE: 0.64 

%section sec:aufgabe_6_regressionsbaume (end) 

\section{Aufgabe 7}

commandline: 

java -cp WEKAPATH weka.classifiers.Bagging -W weka.classifiers.trees.J48 -i -t contact\_lenses.arff -- -U



\section{Aufgabe 9 | Pre-Processing}
Datensets: ionosphere, iris, yeast.

ionosphere non-filter:
Number of Leaves  : 	18

Size of the tree : 	35
=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         321               91.453  %
Incorrectly Classified Instances        30                8.547  %
Kappa statistic                          0.8096
Mean absolute error                      0.0938
Root mean squared error                  0.2901
Relative absolute error                 20.36   %
Root relative squared error             60.4599 %
Total Number of Instances              351

ionosphere filter:
Number of Leaves  : 	21

Size of the tree : 	27

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         313               89.1738 %
Incorrectly Classified Instances        38               10.8262 %
Kappa statistic                          0.7571
Mean absolute error                      0.1333
Root mean squared error                  0.2969
Relative absolute error                 28.9567 %
Root relative squared error             61.8807 %
Total Number of Instances              351     


iris non-filter:
Number of Leaves  : 	5

Size of the tree : 	9

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         144               96      %
Incorrectly Classified Instances         6                4      %
Kappa statistic                          0.94  
Mean absolute error                      0.035 
Root mean squared error                  0.1586
Relative absolute error                  7.8705 %
Root relative squared error             33.6353 %
Total Number of Instances              150     


iris filter:
Number of Leaves  : 	3

Size of the tree : 	4

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         141               94      %
Incorrectly Classified Instances         9                6      %
Kappa statistic                          0.91  
Mean absolute error                      0.0598
Root mean squared error                  0.193 
Relative absolute error                 13.4523 %
Root relative squared error             40.9465 %
Total Number of Instances              150     



yeast non-filter:
Number of Leaves  : 	185

Size of the tree : 	369


=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         831               55.9973 %
Incorrectly Classified Instances       653               44.0027 %
Kappa statistic                          0.4296
Mean absolute error                      0.1015
Root mean squared error                  0.2678
Relative absolute error                 65.2867 %
Root relative squared error             96.0945 %
Total Number of Instances             1484     



yeast filter:
Number of Leaves  : 	64

Size of the tree : 	94

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         877               59.097  %
Incorrectly Classified Instances       607               40.903  %
Kappa statistic                          0.4657
Mean absolute error                      0.1076
Root mean squared error                  0.239 
Relative absolute error                 69.1624 %
Root relative squared error             85.7568 %
Total Number of Instances             1484     



b)

ionosphere:
Number of Leaves  : 	21

Size of the tree : 	27


Time taken to build model: 0.02 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         320               91.1681 %
Incorrectly Classified Instances        31                8.8319 %
Kappa statistic                          0.8043
Mean absolute error                      0.1185
Root mean squared error                  0.2769
Relative absolute error                 25.733  %
Root relative squared error             57.7242 %
Total Number of Instances              351     



iris:
Number of Leaves  : 	3

Size of the tree : 	4


Time taken to build model: 0 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         140               93.3333 %
Incorrectly Classified Instances        10                6.6667 %
Kappa statistic                          0.9   
Mean absolute error                      0.0618
Root mean squared error                  0.2034
Relative absolute error                 13.8998 %
Root relative squared error             43.1411 %
Total Number of Instances              150     

=== Detailed Accuracy By Class ===

               TP Rate   FP Rate   Precision   Recall  F-Measure   ROC Area  Class
                 1         0          1         1         1          1        Iris-setosa
                 0.9       0.05       0.9       0.9       0.9        0.934    Iris-versicolor
                 0.9       0.05       0.9       0.9       0.9        0.939    Iris-virginica
Weighted Avg.    0.933     0.033      0.933     0.933     0.933      0.958

=== Confusion Matrix ===

  a  b  c   <-- classified as
 50  0  0 |  a = Iris-setosa
  0 45  5 |  b = Iris-versicolor
  0  5 45 |  c = Iris-virginica

yeast
Number of Leaves  : 	64

Size of the tree : 	94


Time taken to build model: 0.02 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances         846               57.0081 %
Incorrectly Classified Instances       638               42.9919 %
Kappa statistic                          0.4369
Mean absolute error                      0.1125
Root mean squared error                  0.2444
Relative absolute error                 72.3218 %
Root relative squared error             87.6814 %
Total Number of Instances             1484     





----------------------

letter:
a)
Number of Leaves  : 	1226

Size of the tree : 	2451


Time taken to build model: 4.23 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances       17596               87.98   %
Incorrectly Classified Instances      2404               12.02   %
Kappa statistic                          0.875 
Mean absolute error                      0.0105
Root mean squared error                  0.0903
Relative absolute error                 14.2446 %
Root relative squared error             46.9362 %
Total Number of Instances            20000     


Number of Leaves  : 	9624

Size of the tree : 	10520


Time taken to build model: 0.36 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances       15725               78.625  %
Incorrectly Classified Instances      4275               21.375  %
Kappa statistic                          0.7777
Mean absolute error                      0.0184
Root mean squared error                  0.1145
Relative absolute error                 24.8961 %
Root relative squared error             59.5544 %
Total Number of Instances            20000

b)
Number of Leaves  : 	9624

Size of the tree : 	10520


Time taken to build model: 1 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances       15733               78.665  %
Incorrectly Classified Instances      4267               21.335  %
Kappa statistic                          0.7781
Mean absolute error                      0.0184
Root mean squared error                  0.1146
Relative absolute error                 24.8632 %
Root relative squared error             59.5869 %
Total Number of Instances            20000

segment:
a)
Number of Leaves  : 	39

Size of the tree : 	77


Time taken to build model: 0.09 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances        2239               96.9264 %
Incorrectly Classified Instances        71                3.0736 %
Kappa statistic                          0.9641
Mean absolute error                      0.0104
Root mean squared error                  0.0914
Relative absolute error                  4.2494 %
Root relative squared error             26.1312 %
Total Number of Instances             2310     


Number of Leaves  : 	295

Size of the tree : 	324


Time taken to build model: 0.01 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances        2202               95.3247 %
Incorrectly Classified Instances       108                4.6753 %
Kappa statistic                          0.9455
Mean absolute error                      0.0175
Root mean squared error                  0.1067
Relative absolute error                  7.1348 %
Root relative squared error             30.4966 %
Total Number of Instances             2310

b)

Number of Leaves  : 	295

Size of the tree : 	324


Time taken to build model: 0.05 seconds

=== Stratified cross-validation ===
=== Summary ===

Correctly Classified Instances        2177               94.2424 %
Incorrectly Classified Instances       133                5.7576 %
Kappa statistic                          0.9328
Mean absolute error                      0.0198
Root mean squared error                  0.1165
Relative absolute error                  8.0774 %
Root relative squared error             33.2926 %
Total Number of Instances             2310     



\end{document}
