%!TEX root = main.tex
Performance Normal \\
\begin{tabular}{l|c|c|c|c|c}
	             & yeast & vowel & vehicle &  sick & abalone  \\ \hline
J48              &  56.0 &  81.5 &  72.5   &  98.9 & 21.2     \\ 
\end{tabular}\\ \\


Performance Bagging \\
\begin{tabular}{l|c|c|c|c|c}
Iterations       & yeast & vowel & vehicle &  sick & abalone     \\ \hline
10               &  60.8 & 90.4  &  76.6   & 98.7  &  23.1       \\ \hline
20               &  61.0 & 91.3  &  75.9   & 98.9  &  23.2       \\ \hline
50               &  62.0 & 91.9  &  76.2   & 98.9  &  23.5       \\ \hline
100              &  61.3 & 92.5  &  76.0   & 98.8  &  23.5       \\ 
\end{tabular}\\ \\

Performance AdaBoost \\
\begin{tabular}{l|c|c|c|c|c}
Iterations       & yeast & vowel & vehicle &  sick & abalone     \\ \hline
10               & 56.4  &  93.3 &  76.2   &  99.2 &  21.7       \\ \hline
20               & 58.1  &  95.9 &  77.0   &  99.2 &  21.9       \\ \hline
50               & 58.9  &  96.0 &  78.4   &  99.2 &             \\ \hline
100              & 58.6  &  96.5 &  78.8   &  99.0 &             \\ 
\end{tabular}\\ \\


Performance Random Forests \\
\begin{tabular}{l|c|c|c|c|c}
Number of Trees  & yeast & vowel & vehicle &  sick & abalone     \\ \hline
10               & 57.9  & 96.0  & 77.0    &  98.4 &  22.4       \\ \hline
20               & 61.2  & 98.0  & 76.5    &  98.4 &  23.4       \\ \hline
50               & 61.3  & 98.2  & 76.7    &  98.5 &  23.4       \\ \hline
100              & 61.4  & 98.5  & 76.5    &  98.4 &  23.8       \\ 
\end{tabular}\\ \\

Generell verbessern alle 3 Ensemble Lerner die Performance gegen\"uber dem regul√§ren \emph{J48}. Bei \emph{Bagging} bringt eine erh\"ohte Anzahl der Iteration nur sehr geringe Verbesserungen auf unseren Datensets. Durch \emph{Boosting} kann die Performance um mehrere Prozent steigen, wenn man die Zahl der Iterationen erh\"oht. Bei \emph{Random Forests} h\"angt eine Steigerung der Performance durch eine erh\"ohte Anzahl von Trees stark vom Datensatz ab. 
