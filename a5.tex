
\textbf{Accuracy}

\begin{table}[htb]
	\centering
\begin{tabular}{c|c|c}
                \emph{k-NN}       & \emph{glass} & \emph{kr-vs-kp}  \\ \hline
				\emph{k = 1}  & 59.35  & 96.28  \\ \hline
				\emph{k = 3}  & 57.01  & 96.50  \\ \hline
				\emph{k = 5}  & 58.88  & 96.03  \\ \hline
				\emph{k = 7}  & 57.01  & 95.40  \\ \hline
				\emph{k = 9}  & 56.07  & 95.24  \\ \hline
				\emph{k = 11} & 56.07  & 95.06  
\end{tabular}
\end{table}

H\"ochste cross validation performance liegt bei $k = 1$ bzw $k = 3$. Damit ist der \emph{k-NN} Klassifizierer f\"ur den \emph{glass} Datensatz besser und f\"ur den \emph{kr-vs-kp} Datensatz schlechter als die Entscheidungsbaumlerner.



